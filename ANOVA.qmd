---
title: "R Workshop: ANOVA, ANCOVA & Factorial ANOVA"
author: "Brier Gallihugh, M.S."
date: today
format:
  html:
    theme: default
    code-annotations: select
    self-contained: true
  pdf: default
hyperrefoptions:
  - linktoc=all
toc: true
toc-location: right
toc-depth: 3
warning: FALSE
echo: true
---

## Introduction to ANOVA

## Running ANOVA

```{r running anova}
library(car)
library(psych)
library(multcomp)
library(effects)
library(tidyverse)
library(sjstats)


data <- dplyr::starwars

data <- data %>% 
  dplyr::select(height,mass,hair_color,species,sex) %>% 
  na.omit() %>% 
  filter(species == "Gungan" | species == "Human" | species == "Wookiee") # <1>
  
height_species_aov <- aov(height ~ species, data = data) # <2>
summary(height_species_aov) # <3>

# Post Hoc Test (Tukey)
TukeyHSD(height_species_aov) # <4>
# Bonferroni Adjustment vs Tukey
pairwise.t.test(data$height, data$species, p.adjust.method = "bonferroni") # <5>
```
1. Here we are using the `filter()` function to filter for "Gungan", "Human" and "Wookiee"
2. This is the `aov()` function. Here we are specifying the ANOVA formula.
3. The `summary()` function will give you the output of the ANOVA
4. Because the `species` variable has more than 2 conditions, we might want to figure out which comparisons are statistically different from each other. The `TukeyHSD()` function allows us to perform a post hoc Tukey test
5. Maybe Tukey isn't your favorite correction. Another route might be to use a pairwise t test that corrects for multiple comparisons using a Bonferroni correction. You can do that with the `pairwise.t.test()` function. 

## Assumptions of ANOVA

As ANOVA is just a special case of linear regression, the same assumptions exist for ANOVA that exist for linear regression. We will test each assumption below. The code will look awfully similar to the code used for linear regression previously

### Model Normality

#### Graphical

```{r anova normality graph}
density_plot <- data %>% ggplot(aes(x = height_species_aov$residuals)) +
  geom_histogram(aes(y= after_stat(density)),binwidth = 1) +
  stat_function(fun = dnorm,
                args = list(mean = mean(height_species_aov$residuals),
                            sd = sd(height_species_aov$residuals)),
                col = "blue",
                linewidth = 1) +
  labs(title = "Figure 1. Histogram of Model Residual Scores",
       x = "Model Residuals",
       y = "Density")

density_plot

# OR

qqnorm(height_species_aov$residuals) # <1>
qqline(height_species_aov$residuals, col = "blue") # <1>
```
1.When running the `qqnorm()` and `qqline()` functions at the same time, you will get a qq-plot which will graphically assess the normality of the argument given (in this case the model residuals). The `col` argument simply tells R which color to make the reference line.

#### Statistical

```{r anova normality stat}
psych::describe(height_species_aov$residuals) # <1>
shapiro.test(height_species_aov$residuals)
```
1. Another way to assess normality is to look at the skew and kurtosis of the data. Typically skew and kurtosis between -1 and 1 are acceptable. We can see this using the `describe()` function within the `psych` package.

### Homogeneity of Variance

As with regression, homogeneity of variance is also important for ANOVA. We will graphically and statistically assess this assumption below.

#### Graphical

```{r anova homogeneity graph}
boxplot(data$height ~ data$species) # <1>
```
1. The `boxplot()` function will give us a visual representation of the DV at each level of the IV. We are looking for boxplots that are roughly the same height across each group.

#### Statistical

Statistically, we can assess homogeneity of variance using Levene's Test. Here we want the results to not be statistically significant.

```{r anova homogeneity stat}
leveneTest(data$height ~ data$species) # <1>
```
1. The `leveneTest()` function from the `car` package takes a DV and IV as arguments.

## Introduction to ANCOVA

## Running ANCOVA

ANCOVA refers to any ANOVA model with 2 or more parameters. These models require similar assumptions to ANOVA with a couple of additional ones. Below we will see how to run an ANCOVA and then test its assumptions.

```{r running ancova}
data <- data %>% mutate(species = as.factor(species))
# Type I SS
ancova <- aov(height ~ species + mass, data = data)
summary(ancova) # <1>
# Reversed Order
ancova2 <- aov(height ~ mass + species, data = data)
summary(ancova2) # <2>

car::Anova(ancova2, type = "III") # <3>

# Std Means
summary_data <- data %>% 
  dplyr::group_by(species) %>% 
  dplyr::summarise(n = n(),
                   mean = mean(height))

# Adjust means for covariate effect
adjustedMeans<- effect("species", ancova, se=TRUE) # <4>
summary(adjustedMeans)
adjustedMeans$se

# Post Hoc Tests

posthoc <- multcomp::glht(ancova, linfct = multcomp::mcp(species = "Tukey")) # <5>
summary(posthoc)
confint(posthoc)

# Effect size
sjstats::anova_stats(car::Anova(ancova,type = "III")) # <6>
```
1. This displays our ANCOVA output with species and then mass.
2. This displays our ANCOVA output with mass and then species. We can see that 1 and 2 are different. This is because R by default does a sequential ANCOVA so order matters.
3. To get around this, we can use the `Anova()` function in the `car` package to specify that we want Type III sums of squares. This will then generate an ANCOVA where the order of predictors doesn't matter
4. When having covariates, one might wish to report adjusted means. We can do that using the `effect()` function from the `effects` package. 
5. To run a post hoc analysis, we need to use the `ghlt()` function from the `multcomp` package. There are additional corrections you can do outside of Tukey. To investigate, please see the documentation.
6. To get basic ANOVA effect size statistics, we can use the `anova_stats()` function from the `sjstats` package.

## Assumptions of ANCOVA

ANCOVA requires the same assumptions as ANOVA with two additional assumptions:
1) That the predictor and covariate are independent 
2) The regression slopes are homogeneous

We will test each of the traditional parametric tests as well as the two additional assumptions below.

### Predictor x Covariate Indepenence

#### Statistical

```{r predictor indep anova}
predictor_assumption <- aov(mass ~ species, data = data) # <1>
summary(predictor_assumption)
```
1. To assess this statistically, one needs to run an ANOVA looking at each predictor with each additional parameter. We do not want these to be statistically significant. 

:::{.callout-tip}
Here the statistical test for this assumption is statistically significant (which is bad). It actually means we can't do this (unless we have random assignment)
:::

### Homogeneity of Regression Slopes

#### Statistical

```{r homogeneity of regression slopes stat}
regression_slope_assumption <- aov(height ~ species*mass, data = data)
car::Anova(regression_slope_assumption, type = "III") # <1>
```
1. To test this assumption, one just needs to test the interaction effects within the model. The code for this is shown here.

:::{.callout-tip}
For the above example, the interaction is NOT significant so assumption is met
:::
### Residual Normality (DV ~ IV)

Residual normality is an assumption shared with standard regression. We can assess it the same way we did previously when looking at simple ANOVA. The same is true for the homogeneity of variance assumption.

#### Statistical

```{r ancova residual normality stat}
height_mass_resid <- scale(residuals(aov(height ~ mass, data = data))) # <1>
psych::describe(height_mass_resid) # <2>
shapiro.test(height_mass_resid) # <3>
```
1. The `scale()` function will scale the residuals of the ANOVA. The `residuals()` function pulls out the residuals within the ANOVA
2. Statistical summary of the residuals using the `describe()` function in the `psych` package
3. Statistical test (Shapiro Wilks) of the residuals using the `shapiro.test()` function

#### Graphical

```{r ancova residual normality graph}
hist(height_mass_resid, col = 'beige', # <1>
     main="", xlab = "ANCOVA Residuals (z-score)", # <1>
     probability = TRUE) # <1>
curve(dnorm(x, mean = mean(height_mass_resid), # <1>
            sd = sd(height_mass_resid)), # <1>
            add = TRUE, lwd = 2, col = 'blue') # <1>
```
1. A graphical histogram (with normal distribution overlay) of the model residuals

### Homogeneity of Variance

#### Statistical

```{r homogeneity stat}
# Levene's Test to Assess Equal Variance for Species
car::leveneTest(data$height ~ data$species) # <1>
```
1. A statistical test (Levene's test) of the homogeneity assumption using the `leveneTest()` function in the `car` package.

#### Graphical

```{r homogeneity graph}
# Boxplot Height by Species
boxplot(height ~ species,data=data, main="Height Variance by Species ", # <1>
   xlab="Species", ylab="Height") # <1>
```
1. A visual representation of the homogeneity of variance assumption using a boxplot

### Linearity of CV & DV

The last assumption is that the CV and DV are linearly related. We can test this using the code below graphically.

#### Graphical

```{r ancova linearity graph}
plot(lm(data$height ~ data$mass,data = data), # <1>
     pch = 16, bty = 'l',2) # <1>
```
1. Visual representation of the CV to DV linearity assumption

## Introduction to Factorial ANOVA

## Running Factorial ANOVA

```{r running factorial anova}
library(tidyverse)
factorial_data <- starwars %>% # <1>
  select(mass,homeworld,species) %>% # <2>
  mutate(homeworld = as.factor(homeworld), # <3>
         species = as.factor(species)) %>% # <4>
  filter(homeworld == "Tatooine" | homeworld == "Naboo") %>% # <5>
  filter(species == "Human" | species == "Droid") %>% na.omit() # <6>
# Modeling As Factorial ANOVA
aov_factorial <- aov(mass ~ species*homeworld, data = factorial_data) # <7>
Anova(aov_factorial, type = "III") # <8>

# Modeling As A Regression (For SS Analyses)
reg_fanova <- lm(mass ~ homeworld*species,data = factorial_data) # <9>
summary(reg_fanova) # <10>
```
1. Start with the `starwars` data set
2. Use the `select()` function to pull out mass, homeworld and specices variables
3. Call the `mutate()` function to format the homeworld variable using the `as.factor()` function.
4. Format the species variables as a factor using the `as.factor()` function.
5. Use the `filter()` function to filter for observations with homeworld = "Tatooine" OR "Naboo"
6. Use the `filter()` function to filter for observations with species = "Human" OR "Droid"
7. Create an ANOVA object using the `aov()` function
8. Use the `Anova()` function from the `car()` package to specifiy Type III Sums of Squares
9. Create an Regression object using the `lm()` function
10. Show output of the regression object using the `summary()` function.

## Assumptions of Factorial ANOVA

### Linearity of IV to DV (Regression)

#### Graphical

```{r normality residuals graph}
plot(lm(mass ~ species, data = factorial_data),2) # <1>

plot(lm(mass ~ homeworld, data = factorial_data),2) # <2>
```
1. Plot the residuals of the model using the `plot()` and `lm()` functions for mass on species
2. Plot the residuals of the model using the `plot()` and `lm()` functions for mass on homeworld

#### Statistical

```{r normality residuals stat}
psych::describe(resid(aov_factorial)) # <1>
shapiro.test(resid(aov_factorial)) # <2>
```
1. Statistical summary of the model residuals using the `describe()` function in the `psych` package
2. Statistical test (Shapiro Wilk) of the residuals using the `resid()` and `shapiro.test()` functions

### Homogeneity of Variance (Regression)

#### Graphical

```{r homogeneity of variance fanova graph}
boxplot(factorial_data$mass ~ factorial_data$species) # <1>

boxplot(factorial_data$mass ~ factorial_data$homeworld) # <1>

# Residuals
f_anova_residuals <- scale(residuals(lm(mass ~ species*homeworld, data = factorial_data))) # <3>
f_anova_fitted <- fitted(lm(mass ~ species*homeworld, data = factorial_data)) # <3>

plot(f_anova_residuals ~ f_anova_fitted) # <4>
```
1. Graphical depiction of the homoegeneity assumptions for mass on species and mass on homeworld
2. Residual object of the ANCOVA
3. Fitted object of the ANCOVA
4. Plot of the residual x fitted data using the `plot()` function

#### Statistical

```{r homogeneity variance fanova stat}
leveneTest(factorial_data$mass ~ factorial_data$species) # <1>

leveneTest(factorial_data$mass ~ factorial_data$homeworld) # <2>

leveneTest(factorial_data$mass ~ interaction(factorial_data$homeworld,factorial_data$species)) # <3>
```
1. Levene test of mass x species using `leveneTest()` function
2. Levene test of mass x homeworld using `leveneTest()` function
3. Levene test of mass x species/homeworld interaction using `leveneTest()` function

### Normallity of Residuals

#### Graphical

```{r normality of residuals factorial graph}
plot(aov_factorial,2) # <1>
```
1. Plot ANOVA residuals using `plot()` function

#### Statistical

```{r normality residuals factorial stat}
fanova_residuals <- aov_factorial$residuals # <1>

shapiro.test(fanova_residuals) # <2>

psych::describe(fanova_residuals) # <3>
```
1. Create residual data set
2. Statistical test of residual normality using `shapiro.test()` function
3. Descriptive statistics of residuals using `describe()` function in the `psych` package
